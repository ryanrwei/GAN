{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gzip\n",
    "import os\n",
    "from  six.moves import urllib\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "SOURCE_URL = \"http://yann.lecun.com/exdb/mnist/\"\n",
    "DATA_DIRECTORY =\"data\"\n",
    "\n",
    "image_size = 28\n",
    "num_channels = 1\n",
    "pixel_depth = 255\n",
    "num_labels = 10\n",
    "validation_size = 5000\n",
    "\n",
    "def maybe_download(filename):\n",
    "    if not tf.gfile.Exists(DATA_DIRECTORY):\n",
    "        tf.gfile.MakeDirs(DATA_DIRECTORY)\n",
    "    filepath = os.path.join(DATA_DIRECTORY, filename)\n",
    "\n",
    "    if not tf.gfile.Exists(filepath):\n",
    "        filepath,_ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)  #urlretrieve()方法直接將遠程數據下載到本地\n",
    "        with tf.gfile.GFile(filepath) as f:\n",
    "            size  = f.size()\n",
    "        print('Successfully downloaded', filename, size, 'bytes.')\n",
    "    return filepath\n",
    "\n",
    "def extract_data(filename,num_images,norm_scale = True):\n",
    "    print('Extracting', filename)\n",
    "\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(image_size*image_size*num_images*num_channels)\n",
    "        data = np.frombuffer(buf,dtype = np.uint8).astype(np.float32)\n",
    "        if norm_scale:\n",
    "            data = data/pixel_depth\n",
    "        data = data.reshape(num_images,image_size,image_size,num_channels)\n",
    "        data = np.reshape(data,[num_images,-1])\n",
    "        return data\n",
    "\n",
    "def  extract_labels(filename,num_images):\n",
    "\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "        num_labels_data = len(labels)\n",
    "        one_hot_encoding = np.zeros((num_labels_data,num_labels))\n",
    "        one_hot_encoding[np.arange(num_labels_data),labels] = 1\n",
    "        one_hot_encoding = np.reshape(one_hot_encoding, [-1, num_labels])\n",
    "    return one_hot_encoding\n",
    "\n",
    "def prepare_MNIST_Data():\n",
    "    train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n",
    "    train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n",
    "    test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n",
    "    test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "    train_data = extract_data(train_data_filename,60000)\n",
    "    train_labels = extract_labels(train_labels_filename,60000)\n",
    "    test_data = extract_data(test_data_filename,10000)\n",
    "    test_labels = extract_labels(test_labels_filename,10000)\n",
    "\n",
    "    validation_data = train_data[:validation_size,:]\n",
    "    validation_labels = train_labels[:validation_size,:]\n",
    "    train_data = train_data[validation_size:,:]\n",
    "    train_labels = train_labels[validation_size:,:]\n",
    "\n",
    "    return train_data,train_labels,validation_data,validation_labels,test_data,test_labels\n",
    "\n",
    "def preprocessing_data(data):\n",
    "    \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    config = tf.ConfigProto(allow_soft_placement = True)\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.5)\n",
    "    config.gpu_options.allow_growth = True\n",
    " \n",
    "    sess = tf.InteractiveSession(config = config)\n",
    "    \n",
    "#     sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    data = tf.reshape(data, [-1,28,28,1])\n",
    "    train_data = tf.image.resize_images(data, [64,64])\n",
    "    train_data = (train_data - 0.5) / 0.5\n",
    "    train_data = tf.reshape(train_data,[-1,64*64*1])\n",
    "    train_set = sess.run(train_data)\n",
    "    sess.close()\n",
    "    return train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "class Gan():  \n",
    "    #Gan(sess,[64,64,1],FLAGS.z_d, FLAGS.learning_rate, FLAGS.batch_size)\n",
    "    #Gan(sess,[64,64,1],100, 0.00004, 64)\n",
    "\n",
    "    def __init__(self,sess,data_shape,z_d, learning_rate,batch_size):\n",
    "        self.sess  = sess\n",
    "        self.data_shape = data_shape #[64,64,1]\n",
    "        self.length = self.data_shape[0]*self.data_shape[1]*self.data_shape[2] #64*64*1 = 4096\n",
    "        self.z_d = z_d #100\n",
    "        self.learning_rate = learning_rate  #0.00004\n",
    "        self.batch_size = batch_size #64\n",
    "        self.beta1 = 0.5\n",
    "        self.build_net()\n",
    "\n",
    "    def Generator(self, z, is_training, reuse):\n",
    "        depths = [1024, 512, 256, 128] + [self.data_shape[2]]\n",
    "        with tf.variable_scope(\"Generator\", reuse = reuse):\n",
    "            with tf.variable_scope(\"g_fc1\", reuse = reuse):\n",
    "                output = tf.layers.dense(z, depths[0]*4*4, trainable = is_training)\n",
    "                output = tf.reshape(output, [self.batch_size, 4, 4, depths[0]])\n",
    "                output = tf.nn.relu(tf.layers.batch_normalization(output, training = is_training))\n",
    "\n",
    "            with tf.variable_scope(\"g_dc1\", reuse = reuse):\n",
    "                output = tf.layers.conv2d_transpose(output, depths[1], [5,5], strides =(2,2), padding =\"SAME\", trainable = is_training)\n",
    "                output = tf.nn.relu(tf.layers.batch_normalization(output, training = is_training))\n",
    "\n",
    "            with tf.variable_scope(\"g_dc2\", reuse = reuse):\n",
    "                output = tf.layers.conv2d_transpose(output, depths[2], [5,5], strides = (2,2), padding =\"SAME\", trainable = is_training)\n",
    "                output = tf.nn.relu(tf.layers.batch_normalization(output, training = is_training))\n",
    "\n",
    "            with tf.variable_scope(\"g_dc3\", reuse = reuse):\n",
    "                output = tf.layers.conv2d_transpose(output,depths[3], [5,5], strides = (2,2), padding =\"SAME\", trainable = is_training)\n",
    "                output = tf.nn.relu(tf.layers.batch_normalization(output, training = is_training))\n",
    "\n",
    "            with tf.variable_scope(\"g_dc4\", reuse = reuse):\n",
    "                output = tf.layers.conv2d_transpose(output,depths[4], [5,5], strides = (2,2), padding = \"SAME\", trainable = is_training)\n",
    "                g_logits = tf.nn.tanh(output)\n",
    "\n",
    "        return g_logits\n",
    "\n",
    "    def Discriminator(self,X, is_training, reuse):\n",
    "        depths = [self.data_shape[2]] + [64, 128, 256, 512]   # [1,64,128,256,512]\n",
    "        with tf.variable_scope(\"Discriminator\", reuse = reuse):\n",
    "            with tf.variable_scope(\"d_cv1\", reuse = reuse):\n",
    "                output = tf.layers.conv2d(X, depths[1], [5,5], strides = (2,2), padding =\"SAME\", trainable = is_training)\n",
    "                output = tf.nn.leaky_relu(tf.layers.batch_normalization(output, training = is_training))\n",
    "\n",
    "            with tf.variable_scope(\"d_cv2\", reuse = reuse):\n",
    "                output = tf.layers.conv2d(output, depths[2], [5,5], strides = (2,2), padding =\"SAME\", trainable = is_training)\n",
    "                output = tf.nn.leaky_relu(tf.layers.batch_normalization(output, training = is_training))\n",
    "\n",
    "            with tf.variable_scope(\"d_cv3\", reuse = reuse):\n",
    "                output = tf.layers.conv2d(output, depths[3], [5,5], strides = (2,2), padding = \"SAME\", trainable = is_training)\n",
    "                output = tf.nn.leaky_relu(tf.layers.batch_normalization(output, training = is_training))\n",
    "\n",
    "            with tf.variable_scope(\"d_cv4\", reuse = reuse):\n",
    "                output = tf.layers.conv2d(output, depths[4], [5,5], strides = (2,2), padding =\"SAME\", trainable = is_training)\n",
    "                output = tf.nn.leaky_relu(tf.layers.batch_normalization(output, training = is_training))\n",
    "\n",
    "            with tf.variable_scope(\"d_fc1\", reuse = reuse):\n",
    "                output = tf.layers.flatten(output)\n",
    "                d_logits = tf.layers.dense(output,1, trainable = is_training)\n",
    "\n",
    "            return d_logits\n",
    "\n",
    "    def plot_and_save(self, order, images):\n",
    "        batch_size = len(images)\n",
    "        n = np.int(np.sqrt(batch_size))\n",
    "        image_size = np.shape(images)[2]\n",
    "        n_channel = np.shape(images)[3]\n",
    "        images = np.reshape(images, [-1,image_size,image_size,n_channel])\n",
    "        canvas = np.empty((n * image_size, n * image_size))\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                canvas[i*image_size: (i+1)*image_size , j*image_size:(j+1)*image_size] = images[n*i+j].reshape(64,64)\n",
    "        plt.figure(figsize =(8,8))\n",
    "        plt.imshow(canvas, cmap =\"gray\")\n",
    "        label = \"Epoch: {0}\".format(order+1)\n",
    "        plt.xlabel(label)\n",
    "\n",
    "        if type(order) is str:\n",
    "            file_name = order\n",
    "        else:\n",
    "            file_name = \"Mnist_canvas\" + str(order)\n",
    "\n",
    "        plt.savefig(file_name)\n",
    "        print(os.getcwd())\n",
    "        print(\"Image saved in file: \", file_name)\n",
    "        plt.close()\n",
    "\n",
    "    def build_net(self):\n",
    "        self.X = tf.placeholder(tf.float32 , shape = [None, self.length], name =\"Input_data\")\n",
    "        self.X_img = tf.reshape(self.X, [-1] + self.data_shape)   # (batch_size , 64, 64, 1)\n",
    "        self.z = tf.placeholder(tf.float32, shape = [None, self.z_d], name =\"latent_var\")  #(batch_size , 100)\n",
    "\n",
    "        self.G = self.Generator(self.z, is_training = True, reuse = False)\n",
    "        self.D_fake_logits = self.Discriminator(self.G, is_training = True, reuse = False)\n",
    "        self.D_true_logits = self.Discriminator(self.X_img, is_training = True, reuse = True)\n",
    "\n",
    "        self.G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = self. D_fake_logits, labels = tf.ones_like(self.D_fake_logits)))\n",
    "        self.D_loss_1 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = self.D_true_logits , labels = tf.ones_like(self.D_true_logits)))\n",
    "        self.D_loss_2 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = self.D_fake_logits  , labels = tf.zeros_like(self.D_fake_logits)))\n",
    "        self.D_loss = self.D_loss_1 + self.D_loss_2\n",
    "\n",
    "        total_vars = tf.trainable_variables()\n",
    "        self.d_vars = [var for var in total_vars if  \"d_\" in var.name]\n",
    "        self.g_vars = [var for var in total_vars if  \"g_\" in var.name]\n",
    "\n",
    "\n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "            self.g_optimization = tf.train.AdamOptimizer(learning_rate = self.learning_rate, beta1 = self.beta1).\\\n",
    "                minimize(self.G_loss, var_list = self.g_vars)\n",
    "            self.d_optimization = tf.train.AdamOptimizer(learning_rate = self.learning_rate, beta1 = self.beta1).\\\n",
    "                minimize(self.D_loss, var_list = self.d_vars)\n",
    "        print(\"we successfully make the network\")\n",
    "\n",
    "    def training(self,Data, epoch):  ##(train_data,FLAGS.n_epoch) = ( [55000,4096] , 1 )\n",
    "        start_time = time.time()\n",
    "        \n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "        config = tf.ConfigProto(allow_soft_placement = True)\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.5)\n",
    "        config.gpu_options.allow_growth = True\n",
    "        \n",
    "        sess = tf.InteractiveSession(config = config)\n",
    "        \n",
    "#         sess = tf.Session()\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "\n",
    "        for i in range(epoch):  #epoch\n",
    "            total_batch = int(len(Data)/self.batch_size)  #55000/64 = 859\n",
    "            d_value = 0\n",
    "            g_value = 0\n",
    "            for j in range(total_batch):  #batch\n",
    "                batch_xs = Data[j*self.batch_size:j*self.batch_size + self.batch_size]\n",
    "                z_sampled1 = np.random.uniform(low  = -1.0, high = 1.0, size = [self.batch_size, self.z_d]) #(64, 100)\n",
    "                Op_d, d_= sess.run([self.d_optimization, self.D_loss], feed_dict = {self.X:batch_xs, self.z: z_sampled1})\n",
    "                \n",
    "                z_sampled2 = np.random.uniform(low = -1.0, high = 1.0, size = [self.batch_size, self.z_d])\n",
    "                Op_g, g_= sess.run([self.g_optimization, self.G_loss], feed_dict = {self.X:batch_xs, self.z: z_sampled2})\n",
    "                \n",
    "                self.images_generated = sess.run(self.G, feed_dict = {self.z:z_sampled2})\n",
    "                \n",
    "                d_value += d_/total_batch\n",
    "                g_value +=  g_/ total_batch\n",
    "            \n",
    "            self.plot_and_save(i, self.images_generated)\n",
    "            hour = int((time.time() - start_time)/3600)\n",
    "            min = int(((time.time() - start_time) - 3600*hour)/60)\n",
    "            sec = int((time.time()  - start_time) - 3600*hour - 60*min)\n",
    "            print(\"Time: \",hour,\"h\", min,\"min\",sec ,\"sec\",\"   Epoch: \", i, \"G_loss: \", g_value, \"D_loss: \",d_value)\n",
    "\n",
    "    def testing(self):\n",
    "        self.fake_images = self.generator(self.z, is_training = False, reuse = True)\n",
    "        z_sampled_for_test  = np.random.uniform(low = -1.0, high = 1.0, size = [self.batch_size, self.z_d])\n",
    "        \n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "        config = tf.ConfigProto(allow_soft_placement = True)\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.5)\n",
    "        config.gpu_options.allow_growth = True\n",
    "        \n",
    "        sess = tf.InteractiveSession(config = config)\n",
    "        \n",
    "#         sess = tf.Session()\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        _ = sess.run(self.fake_images, feed_dict  = {self.z: z_sampled_for_test})\n",
    "        self.plot_and_save(\"test_image\", _)\n",
    "        print(\"we have successfully completed the test \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\train-images-idx3-ubyte.gz\n",
      "Extracting data\\t10k-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-28cbe8f9d26c>:25: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-28cbe8f9d26c>:27: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:From <ipython-input-2-28cbe8f9d26c>:30: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-28cbe8f9d26c>:51: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-28cbe8f9d26c>:67: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "we successfully make the network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\python\\tensorflow\\black\\GAN\n",
      "Image saved in file:  Mnist_canvas0\n",
      "Time:  0 h 9 min 5 sec    Epoch:  0 G_loss:  10.605354106745432 D_loss:  0.07755599245928453\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import data\n",
    "# import model\n",
    "\n",
    "flags = tf.app.flags\n",
    "\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "flags.DEFINE_integer(\"z_d\", 100, \"Dimension of z\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.00004, \"learning_rate\")\n",
    "flags.DEFINE_integer(\"batch_size\", 64, \"batch_size\")\n",
    "flags.DEFINE_integer(\"n_epoch\", 1, \"number of epoch\")\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "train_data,train_labels,validation_data,validation_labels,test_data,test_labels = prepare_MNIST_Data()\n",
    "train_data = preprocessing_data(train_data)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config = tf.ConfigProto(allow_soft_placement = True)\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.5)\n",
    "config.gpu_options.allow_growth = True\n",
    " \n",
    "sess = tf.InteractiveSession(config = config)\n",
    "\n",
    "# sess = tf.Session()\n",
    "network = Gan(sess,[64,64,1],FLAGS.z_d, FLAGS.learning_rate, FLAGS.batch_size) \n",
    "sess.run(tf.initialize_all_variables())\n",
    "# tf.global_variables_initializer()\n",
    "network.training(train_data,FLAGS.n_epoch)  #(train_data,FLAGS.n_epoch) = (55000,4096,1)\n",
    "# network.testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okay\n"
     ]
    }
   ],
   "source": [
    "print('okay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
